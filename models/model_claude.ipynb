{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Imbalanced learn imports for handling class imbalance\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4900 feature matrices\n",
      "Original Labels: [  2   3   4   5   6   7   8   9  13  16  17  18  22  23  24  25  26  28\n",
      "  29  30  33  36  38  39  40  42  43  44  46  48  49  50  51  57  65  67\n",
      "  68  69  71  72  73  74  77  78  79  81  82  85  87  88  89  90  92  93\n",
      "  94  96  99 103 104 107 109 110 111 112 114 115]\n",
      "Encoded Labels: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carlos/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/carlos/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/carlos/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Random Forest with SMOTE Results ---\n",
      "Accuracy: 0.0378\n",
      "Cross-validation Scores: [0.03316327 0.03954082 0.0255102  0.04209184 0.0497449 ]\n",
      "Mean CV Score: 0.0380\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class AdvancedSatelliteClassifier:\n",
    "    def __init__(self, data_path='/home/carlos/Documents/fingerprint/features/cell_39'):\n",
    "        \"\"\"\n",
    "        Advanced Satellite Classifier with improved techniques\n",
    "        \n",
    "        Args:\n",
    "            data_path (str): Path to directory containing .npy files\n",
    "        \"\"\"\n",
    "        self.data_path = data_path\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        \n",
    "    def load_data(self, start_idx=1, end_idx=4900):\n",
    "        \"\"\"\n",
    "        Load and preprocess data from .npy files\n",
    "        \n",
    "        Returns:\n",
    "            tuple: X (features), y (encoded labels)\n",
    "        \"\"\"\n",
    "        X, y = [], []\n",
    "        file_count = 0\n",
    "        \n",
    "        for idx in range(start_idx, end_idx + 1):\n",
    "            try:\n",
    "                npy_file = os.path.join(self.data_path, f'features_{idx}.npy')\n",
    "                metadata_file = os.path.join(self.data_path, f'features_{idx}_metadata.json')\n",
    "                \n",
    "                # Skip if files don't exist\n",
    "                if not (os.path.exists(npy_file) and os.path.exists(metadata_file)):\n",
    "                    continue\n",
    "                \n",
    "                # Load features\n",
    "                features = np.load(npy_file)\n",
    "                \n",
    "                # Load metadata\n",
    "                with open(metadata_file, 'r') as f:\n",
    "                    metadata = json.load(f)\n",
    "                \n",
    "                # Flatten the 2D array to 1D for classification\n",
    "                X.append(features.flatten())\n",
    "                y.append(metadata['Satellite_Label'])\n",
    "                \n",
    "                file_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {idx}: {e}\")\n",
    "        \n",
    "        # Convert to numpy arrays\n",
    "        X = np.array(X)\n",
    "        \n",
    "        # Encode labels\n",
    "        y_encoded = self.label_encoder.fit_transform(y)\n",
    "        \n",
    "        print(f\"Loaded {file_count} feature matrices\")\n",
    "        print(\"Original Labels:\", np.unique(y))\n",
    "        print(\"Encoded Labels:\", np.unique(y_encoded))\n",
    "        \n",
    "        return X, y_encoded\n",
    "    \n",
    "    def create_classification_pipelines(self):\n",
    "        \"\"\"\n",
    "        Create multiple classification pipelines with different strategies\n",
    "        \n",
    "        Returns:\n",
    "            dict: Classification pipelines\n",
    "        \"\"\"\n",
    "        # Pipelines with SMOTE for handling class imbalance\n",
    "        pipelines = {\n",
    "            'Random Forest with SMOTE': ImbPipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('smote', SMOTE(random_state=42)),\n",
    "                ('classifier', RandomForestClassifier(\n",
    "                    n_estimators=200, \n",
    "                    max_depth=10, \n",
    "                    min_samples_split=5, \n",
    "                    random_state=42\n",
    "                ))\n",
    "            ]),\n",
    "            \n",
    "            'Gradient Boosting with SMOTE': ImbPipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('smote', SMOTE(random_state=42)),\n",
    "                ('classifier', GradientBoostingClassifier(\n",
    "                    n_estimators=200, \n",
    "                    learning_rate=0.1, \n",
    "                    max_depth=5, \n",
    "                    random_state=42\n",
    "                ))\n",
    "            ]),\n",
    "            \n",
    "            'SVM with SMOTE': ImbPipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('smote', SMOTE(random_state=42)),\n",
    "                ('classifier', SVC(\n",
    "                    kernel='rbf', \n",
    "                    C=10, \n",
    "                    gamma='scale', \n",
    "                    random_state=42\n",
    "                ))\n",
    "            ])\n",
    "        }\n",
    "        \n",
    "        return pipelines\n",
    "    \n",
    "    def train_and_evaluate(self, X, y, test_size=0.2):\n",
    "        \"\"\"\n",
    "        Train and evaluate multiple classification pipelines\n",
    "        \n",
    "        Args:\n",
    "            X (np.array): Features\n",
    "            y (np.array): Encoded labels\n",
    "            test_size (float): Proportion of test set\n",
    "        \n",
    "        Returns:\n",
    "            dict: Performance metrics for each pipeline\n",
    "        \"\"\"\n",
    "        # Split the data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        # Create pipelines\n",
    "        pipelines = self.create_classification_pipelines()\n",
    "        \n",
    "        # Store results\n",
    "        results = {}\n",
    "        \n",
    "        # Evaluate each pipeline\n",
    "        for name, pipeline in pipelines.items():\n",
    "            try:\n",
    "                # Perform cross-validation\n",
    "                cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5)\n",
    "                \n",
    "                # Fit on training data\n",
    "                pipeline.fit(X_train, y_train)\n",
    "                \n",
    "                # Predict on test data\n",
    "                y_pred = pipeline.predict(X_test)\n",
    "                \n",
    "                # Decode predictions back to original labels\n",
    "                original_y_test = self.label_encoder.inverse_transform(y_test)\n",
    "                original_y_pred = self.label_encoder.inverse_transform(y_pred)\n",
    "                \n",
    "                # Store results\n",
    "                results[name] = {\n",
    "                    'accuracy': accuracy_score(y_test, y_pred),\n",
    "                    'cross_val_scores': cv_scores,\n",
    "                    'mean_cv_score': cv_scores.mean(),\n",
    "                    'classification_report': classification_report(\n",
    "                        original_y_test, original_y_pred\n",
    "                    ),\n",
    "                    'confusion_matrix': confusion_matrix(y_test, y_pred)\n",
    "                }\n",
    "                \n",
    "                # Print results\n",
    "                print(f\"\\n--- {name} Results ---\")\n",
    "                print(f\"Accuracy: {results[name]['accuracy']:.4f}\")\n",
    "                print(f\"Cross-validation Scores: {cv_scores}\")\n",
    "                print(f\"Mean CV Score: {cv_scores.mean():.4f}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error with {name}: {e}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def plot_results(self, results):\n",
    "        \"\"\"\n",
    "        Visualize results from different pipelines\n",
    "        \n",
    "        Args:\n",
    "            results (dict): Performance results from train_and_evaluate\n",
    "        \"\"\"\n",
    "        # Plot cross-validation scores\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.title(\"Cross-Validation Scores Comparison\")\n",
    "        cv_scores = [results[name]['cross_val_scores'] for name in results.keys()]\n",
    "        plt.boxplot(cv_scores, labels=list(results.keys()))\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Plot confusion matrices\n",
    "        for name, result in results.items():\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            sns.heatmap(result['confusion_matrix'], annot=True, fmt='d', cmap='Blues')\n",
    "            plt.title(f\"Confusion Matrix - {name}\")\n",
    "            plt.xlabel(\"Predicted Label\")\n",
    "            plt.ylabel(\"True Label\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "# Main execution\n",
    "def main():\n",
    "    try:\n",
    "        # Initialize classifier\n",
    "        classifier = AdvancedSatelliteClassifier()\n",
    "        \n",
    "        # Load data\n",
    "        X, y = classifier.load_data()\n",
    "        \n",
    "        # Train and evaluate\n",
    "        results = classifier.train_and_evaluate(X, y)\n",
    "        \n",
    "        # Plot results\n",
    "        classifier.plot_results(results)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Run the script\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fingerprint",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
